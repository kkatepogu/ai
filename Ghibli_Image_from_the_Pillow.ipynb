{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaw4YpQCWwepWULyKQpaAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkatepogu/ai/blob/main/Ghibli_Image_from_the_Pillow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu0KoMytlFg_",
        "outputId": "acd9a91e-d7ef-406e-e83b-4ad3c5d536f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stylized image saved to output_ghibli_style1.jpg\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load your input image\n",
        "def load_image(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = img.resize((512, 512))  # Resize for the model\n",
        "    img = np.array(img) / 255.0  # Normalize pixel values\n",
        "    # Convert to float32 explicitly\n",
        "    img = img.astype(np.float32)\n",
        "    return img[None, ...]\n",
        "\n",
        "# Save the output image\n",
        "def save_image(image_tensor, output_path):\n",
        "    image = tf.squeeze(image_tensor)  # Remove batch dimension\n",
        "    image = Image.fromarray(np.uint8(image * 255))\n",
        "    image.save(output_path)\n",
        "\n",
        "# Load TensorFlow Hub model for style transfer\n",
        "hub_model = hub.load(\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\")\n",
        "\n",
        "# Paths for input and style images\n",
        "content_image_path = \"/content/Images/WIN_20221231_15_15_16_Pro.jpg\"  # Your image\n",
        "style_image_path = \"/content/Images/ghibli_style_image.jpg\"  # Ghibli reference - Modified to include the full path\n",
        "output_image_path = \"output_ghibli_style1.jpg\"\n",
        "\n",
        "# Load images\n",
        "content_image = load_image(content_image_path)\n",
        "style_image = load_image(style_image_path)\n",
        "\n",
        "# Perform style transfer\n",
        "stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "\n",
        "# Save the output\n",
        "save_image(stylized_image, output_image_path)\n",
        "print(f\"Stylized image saved to {output_image_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "uI4z3qpqnP7t"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JnPqqL12mzl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import tensorflow as tf:** Imports the TensorFlow library, which is a powerful framework for building and training machine learning models, and it's aliased as tf for easier use.\n",
        "\n",
        "**import tensorflow_hub as hub:** Imports TensorFlow Hub, which provides a way to easily use pre-trained machine learning models. It's aliased as hub.\n",
        "\n",
        "**from PIL import Image:** Imports the Image module from the Pillow (PIL) library, which is used for image processing.\n",
        "\n",
        "**import numpy as np:** Imports the NumPy library, which is used for numerical computations, especially with arrays. It's aliased as np."
      ],
      "metadata": {
        "id": "vxQJ6FCPnYw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and Preprocessing Images**"
      ],
      "metadata": {
        "id": "mQ0Nd_SUoo5f"
      }
    },
    {
      "source": [
        "def load_image(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = img.resize((512, 512))  # Resize for the model\n",
        "    img = np.array(img) / 255.0  # Normalize pixel values\n",
        "    # Convert to float32 explicitly\n",
        "    img = img.astype(np.float32)\n",
        "    return img[None, ...]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7c5N5u1Wm3ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, load_image, is designed to:\n",
        "1.\tOpen an image from the specified image_path.\n",
        "2.\tConvert the image to RGB format.\n",
        "3.\tResize the image to 512x512 pixels, which is likely a requirement of the style transfer model.\n",
        "4.\tConvert the image to a NumPy array and normalize its pixel values to be between 0 and 1. This is a common preprocessing step for machine learning models.\n",
        "5.\tConvert the array to float32 data type.\n",
        "6.\tReturn the processed image as a 4D tensor (adding a batch dimension).\n"
      ],
      "metadata": {
        "id": "oNzMLclnomna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Stylized Image"
      ],
      "metadata": {
        "id": "h-t6acTWoLMW"
      }
    },
    {
      "source": [
        "def save_image(image_tensor, output_path):\n",
        "    image = tf.squeeze(image_tensor)  # Remove batch dimension\n",
        "    image = Image.fromarray(np.uint8(image * 255))\n",
        "    image.save(output_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CZqzPrwum4it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, save_image, is designed to:\n",
        "1.\tTake the stylized image tensor (image_tensor) and remove the batch dimension using tf.squeeze.\n",
        "2.\tConvert the tensor back to a Pillow Image object, scaling the pixel values back to the 0-255 range.\n",
        "3.\tSave the image to the specified output_path."
      ],
      "metadata": {
        "id": "69-EVHTFoPRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the Style Transfer Model**"
      ],
      "metadata": {
        "id": "bl7uJblho4hj"
      }
    },
    {
      "source": [
        "hub_model = hub.load(\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kzwHJg_Jm5wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line loads a pre-trained style transfer model from TensorFlow Hub. This specific model is designed for arbitrary image stylization."
      ],
      "metadata": {
        "id": "R5XgKVY2o8Lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Specifying Image Paths**"
      ],
      "metadata": {
        "id": "AVxWd_BIpAN7"
      }
    },
    {
      "source": [
        "content_image_path = \"/content/Images/WIN_20221231_15_15_16_Pro.jpg\"  # Your image\n",
        "style_image_path = \"/content/Images/ghibli_style_image.jpg\"  # Ghibli reference - Modified to include the full path\n",
        "output_image_path = \"output_ghibli_style1.jpg\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "uVrgDeiYm6Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These lines define the paths to the input images and where the output image will be saved.\n",
        "\n",
        "•\tcontent_image_path: Path to the image you want to stylize.\n",
        "\n",
        "•\tstyle_image_path: Path to the image whose style you want to apply.\n",
        "\n",
        "•\toutput_image_path: Path where the stylized image will be saved.\n"
      ],
      "metadata": {
        "id": "cLFssgzDpEE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Performing Style Transfer**"
      ],
      "metadata": {
        "id": "Juua_g6NpQ7q"
      }
    },
    {
      "source": [
        "content_image = load_image(content_image_path)\n",
        "style_image = load_image(style_image_path)\n",
        "\n",
        "stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "\n",
        "save_image(stylized_image, output_image_path)\n",
        "print(f\"Stylized image saved to {output_image_path}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "daxWRRUPm7Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tThe load_image function is called to load and preprocess the content and style images.\n",
        "2.\tThe pre-trained style transfer model (hub_model) is applied to the content and style images to generate the stylized image.\n",
        "3.\tThe save_image function is called to save the stylized image to the specified output path.\n",
        "4.\tA message is printed to the console indicating where the stylized image was saved.\n",
        "\n"
      ],
      "metadata": {
        "id": "gVy7GUfVpVke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In summary,** this code takes two images (a content image and a style image) as input, uses a pre-trained machine learning model to apply the style of the style image to the content image, and saves the resulting stylized image to a file."
      ],
      "metadata": {
        "id": "WtFlSrIspXOd"
      }
    }
  ]
}